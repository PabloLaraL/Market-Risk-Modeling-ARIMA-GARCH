{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ecaeaa2c",
      "metadata": {},
      "source": [
        "# **Riesgo de Mercado en Python**\n",
        "## **Pipeline: Retornos ‚Üí ARIMA (media) ‚Üí GARCH (volatilidad condicional) ‚Üí Forecast ‚Üí (VaR en Parte 2)**\n",
        "\n",
        "**Objetivo:** estimar y proyectar volatilidad condicional con enfoque profesional (separaci√≥n media/varianza) como base para VaR din√°mico.\n",
        "\n",
        "---\n",
        "\n",
        "### **Mapa del notebook (secuencia profesional)**\n",
        "1. Gesti√≥n de datos y retornos  \n",
        "2. Estacionariedad y diagn√≥stico b√°sico  \n",
        "3. Modelo de media (ARIMA) + residuos  \n",
        "4. Evidencia ARCH (clustering)  \n",
        "5. Modelos GARCH/EGARCH/GJR + distribuciones  \n",
        "6. Diagn√≥stico del modelo (residuos estandarizados)  \n",
        "7. Forecast de volatilidad (horizonte H)  \n",
        "8. Modelamienot VaR y Backtesting\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a902bf0e",
      "metadata": {},
      "source": [
        "# **1. Gesti√≥n de Datos Financieros**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "958a4a6d",
      "metadata": {},
      "source": [
        "# **2. Series de Tiempo: Estacionariedad y Modelo de Media (ARIMA)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9a2b829",
      "metadata": {},
      "source": [
        "## BLOQUE 1 ‚Äî Datos y transformaciones\n",
        "\n",
        "- Descarga de datos (Close)\n",
        "- Construcci√≥n de **log-precio** y **log-retornos**\n",
        "- Plots r√°pidos de sanity check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0540bc92",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# BLOQUE 1 ‚Äî LIBRER√çAS + PAR√ÅMETROS\n",
        "# ================================\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "\n",
        "# Par√°metros\n",
        "ticker = \"CHILE.SN\"       # CHILE.SN / BSANTANDER.SN / COLBUN.SN / CFINRENTAS.SN / CMPC.SN\n",
        "start  = \"2015-01-01\"\n",
        "end    = None             # None = hasta hoy\n",
        "\n",
        "import pmdarima as pm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dda5e59",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# BLOQUE 1 ‚Äî DESCARGA + LIMPIEZA\n",
        "# ================================\n",
        "df = yf.download(ticker, start=start, end=end, auto_adjust=False, progress=False)\n",
        "\n",
        "# Normalizar √≠ndice (Datetime), ordenar y limpiar\n",
        "df.index = pd.to_datetime(df.index)\n",
        "df = df.sort_index()\n",
        "df = df.dropna()\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06701d46",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# BLOQUE 1 ‚Äî PRECIOS ‚Üí LOG-RETORNOS\n",
        "# ================================\n",
        "# Nota (buenas pr√°cticas):\n",
        "# Para an√°lisis de retornos/volatilidad/VaR se recomienda usar 'Adj Close'\n",
        "# (ajustado por dividendos y splits) para evitar saltos artificiales.\n",
        "USE_ADJ_CLOSE = True\n",
        "price_col = \"Adj Close\" if (USE_ADJ_CLOSE and \"Adj Close\" in df.columns) else \"Close\"\n",
        "\n",
        "# Serie de precio\n",
        "price = df[price_col].copy()\n",
        "price.name = \"price\"\n",
        "\n",
        "# Log-precio y log-retornos\n",
        "log_price = np.log(price)\n",
        "log_ret = log_price.diff().dropna()\n",
        "log_ret.name = \"log_ret\"\n",
        "\n",
        "print(\"Price column:\", price_col)\n",
        "print(\"Obs price:\", price.shape[0])\n",
        "print(\"Obs log_ret:\", log_ret.shape[0])\n",
        "log_ret.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2d245f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# BLOQUE 1 ‚Äî PLOTS (VISUAL R√ÅPIDO)\n",
        "# ================================\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(price)\n",
        "plt.title(f\"Precio ({price_col}) ‚Äî {ticker}\")\n",
        "plt.xlabel(\"Fecha\"); plt.ylabel(\"Precio\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(log_ret)\n",
        "plt.title(f\"Log-retornos ‚Äî {ticker}\")\n",
        "plt.xlabel(\"Fecha\"); plt.ylabel(\"log return\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca51531c",
      "metadata": {},
      "source": [
        "## BLOQUE 1B (Opcional) ‚Äî Descomposici√≥n estacional\n",
        "\n",
        "Solo para exploraci√≥n visual; no es requisito para ARIMA financiero en precios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d63c241",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ================================\n",
        "# DESCOMPOSICI√ìN (OPCIONAL)\n",
        "# ================================\n",
        "log_price_b = np.log(price.asfreq(\"B\")).ffill().dropna()\n",
        "\n",
        "decomp = sm.tsa.seasonal_decompose(log_price_b, model=\"additive\", period=252)\n",
        "decomp.plot()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e4fcdcb",
      "metadata": {},
      "source": [
        "## BLOQUE 2 ‚Äî Estacionariedad (ADF)\n",
        "\n",
        "En finanzas:\n",
        "- **Precios** suelen NO ser estacionarios (random walk)\n",
        "- **Retornos** suelen ser m√°s cercanos a estacionarios\n",
        "\n",
        "Aqu√≠ aplicamos ADF para confirmar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d88afaa",
      "metadata": {},
      "outputs": [],
      "source": [
        "def adf_test(series: pd.Series, name: str):\n",
        "    result = adfuller(series.dropna())\n",
        "    stat, pval = result[0], result[1]\n",
        "    print(f\"\\nADF Test: {name}\")\n",
        "    print(f\"ADF Statistic : {stat:.4f}\")\n",
        "    print(f\"p-value       : {pval:.6f}\")\n",
        "    if pval < 0.05:\n",
        "        print(\"‚Üí Serie estacionaria\")\n",
        "    else:\n",
        "        print(\"‚Üí Serie NO estacionaria\")\n",
        "\n",
        "adf_test(price, \"Precio ({price_col})\")\n",
        "adf_test(log_ret, \"Log-retornos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07ccd244",
      "metadata": {},
      "source": [
        "## BLOQUE 3 ‚Äî Identificaci√≥n (ACF / PACF)\n",
        "\n",
        "Gu√≠a visual para sugerir √≥rdenes (p, q) en series estacionarias (usamos **log_ret**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8696ba8a",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plot_acf(log_ret, lags=20)\n",
        "plt.title(f\"ACF ‚Äî Log-ret {ticker}\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plot_pacf(log_ret, lags=20, method=\"ywm\")\n",
        "plt.title(f\"PACF ‚Äî Log-ret {ticker}\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "390d3005",
      "metadata": {},
      "source": [
        "## BLOQUE 4 ‚Äî Estimaci√≥n ARIMA autom√°tica (auto_arima) sobre log-ret\n",
        "\n",
        "Usamos **AIC** para seleccionar (p,d,q) con b√∫squeda stepwise.\n",
        "\n",
        "> Nota: modelar en **log-ret** es com√∫n por estabilidad num√©rica y porque el forecast se revierte f√°cil con `exp()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5f47a23",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_p = pm.auto_arima(\n",
        "    log_ret,\n",
        "    start_p=0, start_q=0,\n",
        "    max_p=5, max_q=5,\n",
        "    d=None,              # <-- IMPORTANTE: que el modelo encuentre d\n",
        "    seasonal=False,\n",
        "    stepwise=True,\n",
        "    trace=True,\n",
        "    information_criterion=\"aic\",\n",
        "    suppress_warnings=True\n",
        ")\n",
        "\n",
        "print(model_p.summary())\n",
        "print(\"Best order (precio):\", model_p.order)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b96ac365",
      "metadata": {},
      "source": [
        "## BLOQUE 5 ‚Äî Diagn√≥stico de residuos\n",
        "\n",
        "Objetivo: que los residuos se comporten como **ruido blanco**.\n",
        "\n",
        "Hacemos:\n",
        "- Serie de residuos\n",
        "- Histograma\n",
        "- ACF de residuos\n",
        "- QQ-plot\n",
        "- Test Ljung-Box (p-value > 0.05 es buena se√±al)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "682e71e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "residuos = pd.Series(\n",
        "    model_p.resid(),\n",
        "    index=log_price.index[-len(model_p.resid()):]\n",
        ").dropna()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32b32a87",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(residuos)\n",
        "plt.title(\"Residuos ARIMA (log_ret)\")\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.hist(residuos, bins=30)\n",
        "plt.title(\"Distribuci√≥n residuos\")\n",
        "\n",
        "plt.subplot(2,2,3)\n",
        "sm.graphics.tsa.plot_acf(residuos, lags=40, ax=plt.gca())\n",
        "plt.title(\"ACF residuos\")\n",
        "\n",
        "plt.subplot(2,2,4)\n",
        "sm.qqplot(residuos, line='s', ax=plt.gca())\n",
        "plt.title(\"QQ plot\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "145293c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "lj = acorr_ljungbox(residuos, lags=[10, 20, 30], return_df=True)\n",
        "lj"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db67a529",
      "metadata": {},
      "source": [
        "# **3. Volatilidad Condicional: ARCH/GARCH**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47cf6b2c",
      "metadata": {},
      "source": [
        "## Modelamiento Volatilidad Arch - Garch"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04e37b32",
      "metadata": {},
      "source": [
        "# BLOQUE 7 ‚Äî Hechos estilizados: ¬øhay clustering de volatilidad?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51eb6839",
      "metadata": {},
      "outputs": [],
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ACF retornos\n",
        "plt.figure(figsize=(12,4))\n",
        "plot_acf(log_ret.dropna(), lags=40)\n",
        "plt.title(f\"ACF ‚Äî log_ret ({ticker})\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ACF retornos^2 (clustering)\n",
        "plt.figure(figsize=(12,4))\n",
        "plot_acf((log_ret.dropna()**2), lags=40)\n",
        "plt.title(f\"ACF ‚Äî log_ret^2 ({ticker})  (Volatility Clustering)\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8977cb6c",
      "metadata": {},
      "source": [
        "# BLOQUE 8 ‚Äî Test formal: ARCH-LM (¬øhay heterocedasticidad condicional?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43a45bab",
      "metadata": {},
      "outputs": [],
      "source": [
        "from statsmodels.stats.diagnostic import het_arch\n",
        "\n",
        "# Opci√≥n A: test en retornos\n",
        "arch_test_ret = het_arch(log_ret.dropna(), nlags=12)\n",
        "print(\"ARCH-LM en log_ret\")\n",
        "print(f\"LM Stat: {arch_test_ret[0]:.4f} | p-value: {arch_test_ret[1]:.6f}\")\n",
        "\n",
        "# Opci√≥n B: test en residuos ARIMA (recomendado si ya modelaste media con ARIMA)\n",
        "arch_test_res = het_arch(residuos.dropna(), nlags=12)\n",
        "print(\"\\nARCH-LM en residuos ARIMA\")\n",
        "print(f\"LM Stat: {arch_test_res[0]:.4f} | p-value: {arch_test_res[1]:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "113983e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from arch import arch_model\n",
        "\n",
        "eps = residuos.dropna()\n",
        "\n",
        "arch1 = arch_model(\n",
        "    eps,\n",
        "    mean=\"Zero\",\n",
        "    vol=\"ARCH\",\n",
        "    p=1,\n",
        "    dist=\"t\"\n",
        ")\n",
        "\n",
        "arch1_fit = arch1.fit(disp=\"off\")\n",
        "print(arch1_fit.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c373aa1c",
      "metadata": {},
      "source": [
        "# BLOQUE 9 ‚Äî Modelo base: GARCH(1,1) sobre residuos del ARIMA (enfoque ‚Äúprofesional‚Äù)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c1a41ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install arch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06630049",
      "metadata": {},
      "outputs": [],
      "source": [
        "from arch import arch_model\n",
        "\n",
        "eps = residuos.dropna()\n",
        "\n",
        "garch11 = arch_model(\n",
        "    eps,\n",
        "    mean=\"Zero\",        # porque eps ya son residuos (media ~ 0)\n",
        "    vol=\"GARCH\",\n",
        "    p=1, q=1,\n",
        "    dist=\"t\"            # t-student suele funcionar mejor en finanzas (colas pesadas)\n",
        ")\n",
        "\n",
        "garch11_fit = garch11.fit(disp=\"off\")\n",
        "print(garch11_fit.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca1e3784",
      "metadata": {},
      "source": [
        "# BLOQUE 10 ‚Äî Extraer y graficar volatilidad condicional (œÉ_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca9e73f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cond_vol = garch11_fit.conditional_volatility  # sigma_t\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(cond_vol)\n",
        "plt.title(f\"Volatilidad condicional œÉ_t ‚Äî GARCH(1,1) ({ticker})\")\n",
        "plt.xlabel(\"Fecha\"); plt.ylabel(\"œÉ_t\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d64916b2",
      "metadata": {},
      "source": [
        "# BLOQUE 11 ‚Äî Comparaci√≥n: volatilidad condicional vs hist√≥rica (rolling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de22ca12",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vol hist√≥rica rolling (21 d√≠as h√°biles), sobre retornos (no residuos)\n",
        "vol_hist = log_ret.dropna().rolling(21).std()\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(vol_hist, label=\"Vol hist√≥rica (rolling 21)\")\n",
        "plt.plot(cond_vol, label=\"Vol condicional (GARCH)\", alpha=0.8)\n",
        "plt.title(f\"Volatilidad: hist√≥rica vs condicional ‚Äî {ticker}\")\n",
        "plt.xlabel(\"Fecha\"); plt.ylabel(\"Vol\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09503e2e",
      "metadata": {},
      "source": [
        "# BLOQUE 12 ‚Äî Diagn√≥stico r√°pido del GARCH (residuos estandarizados)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7416798d",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Residuo estandarizado z_t = eps_t / sigma_t\n",
        "std_resid = garch11_fit.std_resid\n",
        "\n",
        "# ACF de z_t^2 (idealmente m√°s limpio)\n",
        "plt.figure(figsize=(12,4))\n",
        "plot_acf((std_resid**2), lags=40)\n",
        "plt.title(\"ACF ‚Äî residuos estandarizados^2 (post-GARCH)\")\n",
        "plt.show()\n",
        "\n",
        "# Ljung-Box en z_t^2\n",
        "lb = acorr_ljungbox(std_resid**2, lags=[10, 20, 30], return_df=True)\n",
        "lb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e65f3632",
      "metadata": {},
      "source": [
        "# BLOQUE 13 ‚Äî Modelos de Volatilidad Asim√©trica: EGARCH y GJR-GARCH (Introspecci√≥n + Comparaci√≥n)\n",
        "üéØ Objetivo del bloque\n",
        "\n",
        "Explorar alternativas a GARCH(1,1) cuando sospechamos que el mercado reacciona distinto ante noticias malas vs buenas (leverage effect), y comparar modelos con AIC/BIC + diagn√≥stico."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e44b60a1",
      "metadata": {},
      "source": [
        "üÖ∞ Punto A ‚Äî EGARCH(1,1)\n",
        "¬øDe qu√© trata?\n",
        "\n",
        "EGARCH (Exponential GARCH) modela la volatilidad en escala logar√≠tmica.\n",
        "\n",
        "Diferencias clave vs GARCH\n",
        "\n",
        "‚úÖ Permite asimetr√≠a con Œ≥ (leverage effect)\n",
        "‚úÖ Asegura œÉ¬≤ > 0 autom√°ticamente (porque modela log œÉ¬≤)\n",
        "‚úÖ Maneja mejor colas y volatilidad extrema en algunos activos\n",
        "\n",
        "Interpretaci√≥n del par√°metro Œ≥:\n",
        "\n",
        "Œ≥ < 0 (t√≠pico en equity): shocks negativos aumentan m√°s la vol que shocks positivos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce566609",
      "metadata": {},
      "outputs": [],
      "source": [
        "from arch import arch_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "eps = residuos.dropna()\n",
        "\n",
        "# EGARCH(1,1)\n",
        "model_egarch = arch_model(\n",
        "    eps,\n",
        "    mean=\"Zero\",\n",
        "    vol=\"EGARCH\",\n",
        "    p=1, q=1,\n",
        "    dist=\"t\"   # colas pesadas t√≠picas en finanzas\n",
        ")\n",
        "\n",
        "res_egarch = model_egarch.fit(disp=\"off\")\n",
        "print(res_egarch.summary())\n",
        "\n",
        "# Volatilidad condicional ajustada\n",
        "vol_egarch = res_egarch.conditional_volatility\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(vol_egarch)\n",
        "plt.title(f\"Volatilidad Condicional ‚Äî EGARCH(1,1) ({ticker})\")\n",
        "plt.xlabel(\"Fecha\"); plt.ylabel(\"œÉ_t\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b65d88f3",
      "metadata": {},
      "source": [
        "üÖ± Punto B ‚Äî GJR-GARCH(1,1)\n",
        "¬øDe qu√© trata?\n",
        "\n",
        "GJR-GARCH agrega un t√©rmino que se activa si el shock fue negativo.\n",
        "\n",
        "Diferencias clave vs GARCH\n",
        "\n",
        "‚úÖ Asimetr√≠a expl√≠cita: si Œµ<0, el shock pesa m√°s\n",
        "‚úÖ Muy usado en equity y riesgo porque es intuitivo\n",
        "üî∏ Requiere restricciones para asegurar positividad/estabilidad\n",
        "\n",
        "Interpretaci√≥n del par√°metro Œ≥ (en GJR):\n",
        "\n",
        "Œ≥ > 0: shocks negativos aumentan m√°s la vol (leverage effect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89469f38",
      "metadata": {},
      "outputs": [],
      "source": [
        "from arch import arch_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "eps = residuos.dropna()\n",
        "\n",
        "# GJR-GARCH(1,1): en arch se implementa como GARCH con o=1 (t√©rmino asim√©trico)\n",
        "model_gjr = arch_model(\n",
        "    eps,\n",
        "    mean=\"Zero\",\n",
        "    vol=\"GARCH\",\n",
        "    p=1, o=1, q=1,\n",
        "    dist=\"t\"\n",
        ")\n",
        "\n",
        "res_gjr = model_gjr.fit(disp=\"off\")\n",
        "print(res_gjr.summary())\n",
        "\n",
        "# Volatilidad condicional ajustada\n",
        "vol_gjr = res_gjr.conditional_volatility\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(vol_gjr)\n",
        "plt.title(f\"Volatilidad Condicional ‚Äî GJR-GARCH(1,1) ({ticker})\")\n",
        "plt.xlabel(\"Fecha\"); plt.ylabel(\"œÉ_t\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6949c715",
      "metadata": {},
      "source": [
        "# BLOQUE 13.1 ‚Äî Graficos de distintas volatilidades"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bcd7f19",
      "metadata": {},
      "outputs": [],
      "source": [
        "from arch import arch_model\n",
        "\n",
        "# === Funciones estilo profe pero para eps (residuos ARIMA) ===\n",
        "def fit_garch(eps, dist='normal'):\n",
        "    model = arch_model(eps, mean=\"Zero\", vol='GARCH', p=1, q=1, dist=dist)\n",
        "    results = model.fit(disp='off')\n",
        "    return results\n",
        "\n",
        "def fit_egarch(eps, dist='normal'):\n",
        "    model = arch_model(eps, mean=\"Zero\", vol='EGARCH', p=1, q=1, dist=dist)\n",
        "    results = model.fit(disp='off')\n",
        "    return results\n",
        "\n",
        "def fit_gjr_garch(eps, dist='normal'):\n",
        "    model = arch_model(eps, mean=\"Zero\", vol='GARCH', p=1, o=1, q=1, dist=dist)\n",
        "    results = model.fit(disp='off')\n",
        "    return results\n",
        "\n",
        "#########################################################################################\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "eps = residuos.dropna()\n",
        "\n",
        "# 1) Ajuste con Normal\n",
        "res_garch_n  = fit_garch(eps, dist='normal')\n",
        "res_egarch_n = fit_egarch(eps, dist='normal')\n",
        "res_gjr_n    = fit_gjr_garch(eps, dist='normal')\n",
        "\n",
        "# 2) Ajuste con t-student\n",
        "res_garch_t  = fit_garch(eps, dist='t')\n",
        "res_egarch_t = fit_egarch(eps, dist='t')\n",
        "res_gjr_t    = fit_gjr_garch(eps, dist='t')\n",
        "\n",
        "# 3) Ajuste con skewt (asim√©trica)\n",
        "res_garch_s  = fit_garch(eps, dist='skewt')\n",
        "res_egarch_s = fit_egarch(eps, dist='skewt')\n",
        "res_gjr_s    = fit_gjr_garch(eps, dist='skewt')\n",
        "\n",
        "########################################################################################\n",
        "\n",
        "def plot_vols(eps, res_garch, res_egarch, res_gjr, title=\"\"):\n",
        "    df = pd.DataFrame({\n",
        "        \"eps\": eps,\n",
        "        \"GARCH(1,1)\": res_garch.conditional_volatility,\n",
        "        \"EGARCH(1,1)\": res_egarch.conditional_volatility,\n",
        "        \"GJR-GARCH(1,1)\": res_gjr.conditional_volatility\n",
        "    })\n",
        "\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.plot(df[\"eps\"], label=\"eps (residuos)\", color=\"gray\", alpha=0.6)\n",
        "    plt.plot(df[\"GARCH(1,1)\"], label=\"GARCH(1,1)\", alpha=0.8)\n",
        "    plt.plot(df[\"EGARCH(1,1)\"], label=\"EGARCH(1,1)\", alpha=0.8)\n",
        "    plt.plot(df[\"GJR-GARCH(1,1)\"], label=\"GJR-GARCH(1,1)\", alpha=0.8)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Tiempo\")\n",
        "    plt.ylabel(\"Residuo / Volatilidad\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "#########################################################################################\n",
        "\n",
        "plot_vols(eps, res_garch_n, res_egarch_n, res_gjr_n, title=\"Volatilidad estimada (Normal)\")\n",
        "plot_vols(eps, res_garch_t, res_egarch_t, res_gjr_t, title=\"Volatilidad estimada (t-student)\")\n",
        "plot_vols(eps, res_garch_s, res_egarch_s, res_gjr_s, title=\"Volatilidad estimada (skewt)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6e36788",
      "metadata": {},
      "source": [
        "# BLOQUE 14 ‚Äî Forecast de Volatilidad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af588d30",
      "metadata": {},
      "outputs": [],
      "source": [
        "h = 20\n",
        "n_sim = 5000  # puedes bajar a 1000 si va lento\n",
        "\n",
        "# Forecast (multi-step) usando simulaci√≥n\n",
        "fcast_garch  = garch11_fit.forecast(horizon=h, method=\"simulation\", simulations=n_sim, reindex=False)\n",
        "fcast_egarch = res_egarch.forecast(horizon=h, method=\"simulation\", simulations=n_sim, reindex=False)\n",
        "fcast_gjr    = res_gjr.forecast(horizon=h, method=\"simulation\", simulations=n_sim, reindex=False)\n",
        "\n",
        "# Extraer sigma forecast: sqrt(var) de la √∫ltima fila\n",
        "sigma_garch  = np.sqrt(fcast_garch.variance.values[-1])\n",
        "sigma_egarch = np.sqrt(fcast_egarch.variance.values[-1])\n",
        "sigma_gjr    = np.sqrt(fcast_gjr.variance.values[-1])\n",
        "\n",
        "df_forecast = pd.DataFrame({\n",
        "    \"h\": np.arange(1, h+1),\n",
        "    \"GARCH(1,1)\": sigma_garch,\n",
        "    \"EGARCH(1,1)\": sigma_egarch,\n",
        "    \"GJR-GARCH(1,1)\": sigma_gjr\n",
        "})\n",
        "\n",
        "display(df_forecast)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(df_forecast[\"h\"], df_forecast[\"GARCH(1,1)\"], marker=\"o\", label=\"GARCH\")\n",
        "plt.plot(df_forecast[\"h\"], df_forecast[\"EGARCH(1,1)\"], marker=\"o\", label=\"EGARCH\")\n",
        "plt.plot(df_forecast[\"h\"], df_forecast[\"GJR-GARCH(1,1)\"], marker=\"o\", label=\"GJR-GARCH\")\n",
        "\n",
        "plt.title(f\"Forecast de Volatilidad (œÉ) ‚Äî {h} d√≠as (simulation)\")\n",
        "plt.xlabel(\"Horizonte (d√≠as)\")\n",
        "plt.ylabel(\"Sigma forecast\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc1e3801",
      "metadata": {},
      "source": [
        "# BLOQUE 15 ‚Äî Value at Risk (VaR): Enfoques Comparativos\n",
        "\n",
        "El Value at Risk (VaR) mide la p√©rdida m√°xima esperada en un horizonte dado\n",
        "con un nivel de confianza determinado.\n",
        "\n",
        "En este bloque implementaremos tres enfoques cl√°sicos:\n",
        "\n",
        "1. VaR Param√©trico (Modelo condicional ARIMA + GARCH)\n",
        "2. VaR Hist√≥rico\n",
        "3. VaR Monte Carlo\n",
        "4. Extensi√≥n: Monte Carlo Multivariado (Cholesky)\n",
        "\n",
        "El objetivo es comparar sus fundamentos, supuestos y diferencias."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f7efef4",
      "metadata": {},
      "source": [
        "## 15.1 VaR Param√©trico Condicional\n",
        "\n",
        "Se basa en:\n",
        "\n",
        "VaR_t = ŒºÃÇ_t + q_Œ± ¬∑ œÉÃÇ_t\n",
        "\n",
        "Ventajas:\n",
        "- Captura volatilidad din√°mica\n",
        "- Permite colas pesadas (t-student)\n",
        "\n",
        "Desventajas:\n",
        "- Depende del modelo\n",
        "- Sensible a mala especificaci√≥n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a1c7c3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm, t\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Definir el √≠ndice \"v√°lido\" para VaR\n",
        "# ----------------------------\n",
        "# En este notebook, el GARCH se ajusta sobre eps = residuos.dropna()\n",
        "# -> su volatilidad condicional (sigma_t) est√° indexada igual que eps.\n",
        "# Para comparar r_t vs VaR_t de forma correcta, trabajaremos sobre ese mismo √≠ndice.\n",
        "try:\n",
        "    idx = residuos.dropna().index\n",
        "except Exception:\n",
        "    idx = log_ret.dropna().index\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Base dataframe con retornos y media condicional\n",
        "# ----------------------------\n",
        "df_var = pd.DataFrame(index=idx)\n",
        "\n",
        "# Retornos observados (alineados al mismo √≠ndice)\n",
        "df_var[\"r\"] = log_ret.reindex(idx).astype(float)\n",
        "\n",
        "# Media condicional (ARIMA). Si no existe, asumimos 0 (muy com√∫n en pr√°ctica).\n",
        "try:\n",
        "    df_var[\"mu\"] = arima_res.fittedvalues.reindex(idx).astype(float)\n",
        "except Exception:\n",
        "    df_var[\"mu\"] = 0.0\n",
        "\n",
        "df_var[\"mu\"] = df_var[\"mu\"].fillna(0.0)\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Volatilidad condicional: modelo seleccionado\n",
        "# ----------------------------\n",
        "# Modelo final (puedes cambiar a res_garch_t o res_egarch_t si quieres)\n",
        "garch_res = res_gjr_t\n",
        "\n",
        "# sigma_t (ya viene alineada al √≠ndice de eps)\n",
        "sigma_series = pd.Series(garch_res.conditional_volatility, index=idx, name=\"sigma\")\n",
        "df_var[\"sigma\"] = sigma_series\n",
        "\n",
        "# Limpieza final\n",
        "df_var = df_var.dropna(subset=[\"r\", \"mu\", \"sigma\"]).copy()\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Cuantiles: t-Student estandarizada a var=1\n",
        "# ----------------------------\n",
        "# Nota: la t est√°ndar tiene Var = nu/(nu-2). Para shocks con Var=1:\n",
        "# q_std = t_ppf(alpha, nu) * sqrt((nu-2)/nu)\n",
        "if \"nu\" not in garch_res.params.index:\n",
        "    raise KeyError(\"No encontr√© 'nu' en garch_res.params. Revisa garch_res.params.index\")\n",
        "\n",
        "nu = float(garch_res.params[\"nu\"])\n",
        "\n",
        "def q_student_std(alpha: float) -> float:\n",
        "    return t.ppf(alpha, df=nu) * np.sqrt((nu - 2) / nu)\n",
        "\n",
        "alphas = {\"VaR_95\": 0.05, \"VaR_99\": 0.01}\n",
        "\n",
        "for name, a in alphas.items():\n",
        "    df_var[name] = df_var[\"mu\"] + q_student_std(a) * df_var[\"sigma\"]\n",
        "\n",
        "# ----------------------------\n",
        "# 5) Gr√°fico (retornos vs VaR)\n",
        "# ----------------------------\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(df_var.index, df_var[\"r\"], label=\"Retornos\", alpha=0.6)\n",
        "plt.plot(df_var.index, df_var[\"VaR_95\"], label=\"VaR 95%\")\n",
        "plt.plot(df_var.index, df_var[\"VaR_99\"], label=\"VaR 99%\")\n",
        "plt.title(\"VaR Param√©trico Din√°mico ‚Äî GJR-GARCH (t)\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "df_var.tail()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f52d472a",
      "metadata": {},
      "source": [
        "## 15.2 VaR Hist√≥rico\n",
        "\n",
        "El VaR hist√≥rico no asume distribuci√≥n param√©trica.\n",
        "\n",
        "Se calcula directamente como el percentil emp√≠rico\n",
        "de los retornos pasados.\n",
        "\n",
        "VaR_Œ± = Percentil_Œ±(r_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4df18d62",
      "metadata": {},
      "outputs": [],
      "source": [
        "# VaR hist√≥rico global\n",
        "var_hist_95 = np.percentile(log_ret.dropna(), 5)\n",
        "var_hist_99 = np.percentile(log_ret.dropna(), 1)\n",
        "\n",
        "print(\"VaR Hist√≥rico 95%:\", var_hist_95)\n",
        "print(\"VaR Hist√≥rico 99%:\", var_hist_99)\n",
        "\n",
        "# Rolling 250 d√≠as (~1 a√±o burs√°til)\n",
        "window = 250\n",
        "\n",
        "df_var[\"VaR_hist_95\"] = df_var[\"r\"].rolling(window).quantile(0.05)\n",
        "df_var[\"VaR_hist_99\"] = df_var[\"r\"].rolling(window).quantile(0.01)\n",
        "\n",
        "df_var[[\"r\", \"VaR_hist_95\", \"VaR_hist_99\"]].dropna().tail()\n",
        "\n",
        "plt.figure(figsize=(13,6))\n",
        "\n",
        "plt.plot(df_var.index, df_var[\"r\"], \n",
        "         color=\"black\", alpha=0.5, label=\"Retornos\")\n",
        "\n",
        "plt.plot(df_var.index, df_var[\"VaR_hist_95\"], \n",
        "         color=\"blue\", linewidth=1.5, label=\"VaR Hist 95%\")\n",
        "\n",
        "plt.plot(df_var.index, df_var[\"VaR_hist_99\"], \n",
        "         color=\"purple\", linewidth=1.5, label=\"VaR Hist 99%\")\n",
        "\n",
        "plt.title(\"VaR Hist√≥rico Rolling (250 d√≠as)\", fontsize=14)\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ef0731a",
      "metadata": {},
      "source": [
        "## 15.3 VaR Monte Carlo (Univariado)\n",
        "\n",
        "Se simulan N escenarios para el retorno futuro:\n",
        "\n",
        "r_{t+1} = ŒºÃÇ_t + œÉÃÇ_t ¬∑ Œµ\n",
        "\n",
        "donde Œµ sigue la distribuci√≥n estimada (normal o t).\n",
        "\n",
        "El VaR se calcula como el percentil de la distribuci√≥n simulada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1e869ef",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# Monte Carlo VaR (1 d√≠a)\n",
        "# ==============================\n",
        "N = 20000\n",
        "\n",
        "last_mu = df_var[\"mu\"].iloc[-1]\n",
        "last_sigma = df_var[\"sigma\"].iloc[-1]\n",
        "nu = garch_res.params[\"nu\"]\n",
        "\n",
        "# shocks t estandarizados\n",
        "shocks = t.rvs(df=nu, size=N) * np.sqrt((nu-2)/nu)\n",
        "\n",
        "sim_returns = last_mu + last_sigma * shocks\n",
        "\n",
        "mc_var_95 = np.percentile(sim_returns, 5)\n",
        "mc_var_99 = np.percentile(sim_returns, 1)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.hist(sim_returns, bins=100, density=True, alpha=0.6)\n",
        "plt.axvline(mc_var_95, color=\"orange\", label=\"MC VaR 95%\")\n",
        "plt.axvline(mc_var_99, color=\"red\", label=\"MC VaR 99%\")\n",
        "\n",
        "plt.title(\"Monte Carlo ‚Äî Distribuci√≥n Simulada Retorno 1 d√≠a\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Monte Carlo VaR 95%:\", mc_var_95)\n",
        "print(\"Monte Carlo VaR 99%:\", mc_var_99)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61d00b64",
      "metadata": {},
      "source": [
        "## 15.4 Monte Carlo Multivariado (Cholesky)\n",
        "\n",
        "Cuando trabajamos con portafolios, necesitamos simular\n",
        "retornos correlacionados.\n",
        "\n",
        "Si Œ£ es la matriz de covarianza, podemos usar\n",
        "la descomposici√≥n de Cholesky:\n",
        "\n",
        "Œ£ = L L'\n",
        "\n",
        "Simulamos:\n",
        "\n",
        "Z ~ N(0,I)\n",
        "Œµ = L Z\n",
        "\n",
        "As√≠ obtenemos shocks correlacionados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfc0528d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================\n",
        "# Monte Carlo Multivariado (Ejemplo)\n",
        "# ==============================\n",
        "\n",
        "# Supongamos retornos de dos activos\n",
        "returns_matrix = pd.concat([log_ret, log_ret.shift(1)], axis=1).dropna()\n",
        "returns_matrix.columns = [\"Asset1\", \"Asset2\"]\n",
        "\n",
        "cov_matrix = returns_matrix.cov().values\n",
        "L = np.linalg.cholesky(cov_matrix)\n",
        "\n",
        "N = 20000\n",
        "Z = np.random.normal(size=(2, N))\n",
        "correlated_shocks = L @ Z\n",
        "\n",
        "sim_portfolio = correlated_shocks.sum(axis=0)\n",
        "\n",
        "portfolio_var_95 = np.percentile(sim_portfolio, 5)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.hist(sim_portfolio, bins=100, density=True, alpha=0.6)\n",
        "plt.axvline(portfolio_var_95, color=\"red\", label=\"Portfolio VaR 95%\")\n",
        "\n",
        "plt.title(\"Monte Carlo Multivariado (Cholesky)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Portfolio VaR 95%:\", portfolio_var_95)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55c011d9",
      "metadata": {},
      "source": [
        "## 15.5 Comparaci√≥n de Enfoques\n",
        "\n",
        "| M√©todo        | Supuestos | Din√°mico | Pros | Contras |\n",
        "|--------------|----------|----------|------|---------|\n",
        "| Param√©trico  | S√≠       | S√≠       | Flexible | Depende del modelo |\n",
        "| Hist√≥rico    | No       | No       | Simple | No captura cambios estructurales |\n",
        "| Monte Carlo  | S√≠       | S√≠       | Muy flexible | Computacionalmente intensivo |\n",
        "\n",
        "En la pr√°ctica bancaria, el VaR param√©trico condicional\n",
        "es com√∫n en market risk, mientras que Monte Carlo\n",
        "es est√°ndar para portafolios complejos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8365a638",
      "metadata": {},
      "source": [
        "# BLOQUE 16 ‚Äî Backtesting del VaR (Validaci√≥n Cuantitativa)\n",
        "\n",
        "## 16.1 ¬øQu√© es backtesting y por qu√© se hace?\n",
        "\n",
        "El VaR es una predicci√≥n probabil√≠stica:\n",
        "- VaR 99% significa que esperamos violaciones ~1% de los d√≠as.\n",
        "- VaR 95% significa violaciones ~5% de los d√≠as.\n",
        "\n",
        "**Backtesting** es comparar el VaR calculado con los retornos realmente observados para verificar si el modelo:\n",
        "\n",
        "1) **Tiene la cobertura correcta** (frecuencia de violaciones ‚âà Œ±)  \n",
        "2) **No tiene clustering de violaciones** (violaciones independientes en el tiempo)\n",
        "\n",
        "En la pr√°ctica cuant (bancos/AFPs/mesas), backtesting responde:\n",
        "- ¬øEl VaR subestima o sobreestima riesgo?\n",
        "- ¬øLas violaciones ocurren de forma aleatoria (como deber√≠a) o se agrupan (modelo mal especificado)?\n",
        "- ¬øEl modelo reacciona suficientemente r√°pido en shocks?\n",
        "\n",
        "---\n",
        "\n",
        "## 16.2 Qu√© buscamos (criterios profesionales)\n",
        "\n",
        "### A) Cobertura incondicional (Kupiec)\n",
        "Eval√∫a si el porcentaje observado de violaciones coincide con el porcentaje esperado Œ±.\n",
        "\n",
        "- H0: P(violaci√≥n) = Œ±  \n",
        "- Si rechazamos H0 ‚Üí VaR est√° mal calibrado (muy conservador o subestima riesgo)\n",
        "\n",
        "### B) Independencia de violaciones (Christoffersen)\n",
        "Eval√∫a si las violaciones son independientes (no deber√≠an agruparse).\n",
        "\n",
        "- H0: las violaciones no dependen de la violaci√≥n previa  \n",
        "- Si rechazamos H0 ‚Üí hay **clustering** (t√≠pico cuando la volatilidad cambia r√°pido y el modelo no la capta)\n",
        "\n",
        "### C) Cobertura condicional (Christoffersen completo)\n",
        "Combina ambas:\n",
        "- Cobertura correcta + Independencia correcta\n",
        "\n",
        "---\n",
        "\n",
        "## 16.3 Interpretaci√≥n cuant (c√≥mo lo usan en la realidad)\n",
        "\n",
        "Un VaR \"bueno\" t√≠picamente:\n",
        "- No rechaza Kupiec (p-value alto)\n",
        "- No rechaza Independencia (p-value alto)\n",
        "- No rechaza Cobertura condicional\n",
        "\n",
        "Adem√°s se revisa:\n",
        "- N√∫mero esperado vs observado de violaciones\n",
        "- Gr√°fico de violaciones en el tiempo\n",
        "- Si las violaciones se concentran en crisis (normal) pero sin clustering excesivo\n",
        "\n",
        "> Nota: Esto es el coraz√≥n del control de modelos (Model Risk / Market Risk Validation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e3fee19",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# ============================================================\n",
        "# 16.0 Helpers\n",
        "# ============================================================\n",
        "\n",
        "def make_hits(df, var_col, r_col=\"r\"):\n",
        "    \"\"\"\n",
        "    Hit = 1 si hay violaci√≥n (retorno < VaR), 0 si no.\n",
        "    Devuelve serie alineada y sin NaN.\n",
        "    \"\"\"\n",
        "    tmp = df[[r_col, var_col]].dropna().copy()\n",
        "    hit = (tmp[r_col] < tmp[var_col]).astype(int)\n",
        "    hit.name = f\"hit_{var_col}\"\n",
        "    return hit\n",
        "\n",
        "def kupiec_test(hit, alpha):\n",
        "    \"\"\"\n",
        "    Kupiec (Unconditional Coverage) LRuc test.\n",
        "    H0: P(hit=1) = alpha\n",
        "    \"\"\"\n",
        "    x = int(hit.sum())\n",
        "    T = int(hit.count())\n",
        "    phat = x / T if T > 0 else np.nan\n",
        "\n",
        "    # evitar logs inv√°lidos si x=0 o x=T\n",
        "    eps = 1e-12\n",
        "    phat_c = np.clip(phat, eps, 1 - eps)\n",
        "    alpha_c = np.clip(alpha, eps, 1 - eps)\n",
        "\n",
        "    # log-likelihoods\n",
        "    ll_null = x * np.log(alpha_c) + (T - x) * np.log(1 - alpha_c)\n",
        "    ll_alt  = x * np.log(phat_c)  + (T - x) * np.log(1 - phat_c)\n",
        "\n",
        "    LRuc = -2 * (ll_null - ll_alt)\n",
        "    pval = 1 - chi2.cdf(LRuc, df=1)\n",
        "\n",
        "    return {\"T\": T, \"x\": x, \"phat\": phat, \"LRuc\": LRuc, \"pvalue\": pval}\n",
        "\n",
        "def christoffersen_independence_test(hit):\n",
        "    \"\"\"\n",
        "    Christoffersen independence test (LRind).\n",
        "    H0: hits independientes (Markov de orden 0)\n",
        "    Se basa en conteos de transiciones:\n",
        "    N00, N01, N10, N11\n",
        "    \"\"\"\n",
        "    h = hit.dropna().astype(int).values\n",
        "    if len(h) < 2:\n",
        "        return {\"N00\": np.nan, \"N01\": np.nan, \"N10\": np.nan, \"N11\": np.nan,\n",
        "                \"LRind\": np.nan, \"pvalue\": np.nan}\n",
        "\n",
        "    h_lag = h[:-1]\n",
        "    h_cur = h[1:]\n",
        "\n",
        "    N00 = int(((h_lag == 0) & (h_cur == 0)).sum())\n",
        "    N01 = int(((h_lag == 0) & (h_cur == 1)).sum())\n",
        "    N10 = int(((h_lag == 1) & (h_cur == 0)).sum())\n",
        "    N11 = int(((h_lag == 1) & (h_cur == 1)).sum())\n",
        "\n",
        "    # probabilidades condicionales\n",
        "    eps = 1e-12\n",
        "    pi01 = N01 / (N00 + N01) if (N00 + N01) > 0 else 0.0\n",
        "    pi11 = N11 / (N10 + N11) if (N10 + N11) > 0 else 0.0\n",
        "\n",
        "    # probabilidad incondicional\n",
        "    pi = (N01 + N11) / (N00 + N01 + N10 + N11) if (N00 + N01 + N10 + N11) > 0 else 0.0\n",
        "\n",
        "    # clip para logs\n",
        "    pi01 = float(np.clip(pi01, eps, 1 - eps))\n",
        "    pi11 = float(np.clip(pi11, eps, 1 - eps))\n",
        "    pi   = float(np.clip(pi,   eps, 1 - eps))\n",
        "\n",
        "    # log-likelihoods\n",
        "    ll_ind = (N00 * np.log(1 - pi01) + N01 * np.log(pi01) +\n",
        "              N10 * np.log(1 - pi11) + N11 * np.log(pi11))\n",
        "\n",
        "    ll_iid = ((N00 + N10) * np.log(1 - pi) + (N01 + N11) * np.log(pi))\n",
        "\n",
        "    LRind = -2 * (ll_iid - ll_ind)\n",
        "    pval = 1 - chi2.cdf(LRind, df=1)\n",
        "\n",
        "    return {\"N00\": N00, \"N01\": N01, \"N10\": N10, \"N11\": N11, \"LRind\": LRind, \"pvalue\": pval}\n",
        "\n",
        "def christoffersen_conditional_coverage(hit, alpha):\n",
        "    \"\"\"\n",
        "    Christoffersen conditional coverage (LRcc) = LRuc + LRind\n",
        "    \"\"\"\n",
        "    uc = kupiec_test(hit, alpha)\n",
        "    ind = christoffersen_independence_test(hit)\n",
        "\n",
        "    LRcc = uc[\"LRuc\"] + ind[\"LRind\"]\n",
        "    pval = 1 - chi2.cdf(LRcc, df=2)\n",
        "\n",
        "    return {\"LRcc\": LRcc, \"pvalue\": pval, \"uc\": uc, \"ind\": ind}\n",
        "\n",
        "# ============================================================\n",
        "# 16.1 Backtesting para VaR 95% y 99%\n",
        "# ============================================================\n",
        "\n",
        "tests = {}\n",
        "\n",
        "for var_col, alpha in [(\"VaR_95\", 0.05), (\"VaR_99\", 0.01)]:\n",
        "    hit = make_hits(df_var, var_col=var_col, r_col=\"r\")\n",
        "    cc = christoffersen_conditional_coverage(hit, alpha)\n",
        "\n",
        "    tests[var_col] = {\n",
        "        \"alpha\": alpha,\n",
        "        \"T\": cc[\"uc\"][\"T\"],\n",
        "        \"x\": cc[\"uc\"][\"x\"],\n",
        "        \"phat\": cc[\"uc\"][\"phat\"],\n",
        "        \"LRuc\": cc[\"uc\"][\"LRuc\"],\n",
        "        \"p_uc\": cc[\"uc\"][\"pvalue\"],\n",
        "        \"LRind\": cc[\"ind\"][\"LRind\"],\n",
        "        \"p_ind\": cc[\"ind\"][\"pvalue\"],\n",
        "        \"LRcc\": cc[\"LRcc\"],\n",
        "        \"p_cc\": cc[\"pvalue\"],\n",
        "    }\n",
        "\n",
        "results_bt = pd.DataFrame(tests).T\n",
        "results_bt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93c7dcd2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# 16.2 Gr√°fico de violaciones (hits) para VaR 99%\n",
        "# ============================================================\n",
        "\n",
        "hit_99 = make_hits(df_var, \"VaR_99\", \"r\")\n",
        "tmp_99 = df_var[[\"r\", \"VaR_99\"]].dropna().copy()\n",
        "viol_99 = tmp_99[tmp_99[\"r\"] < tmp_99[\"VaR_99\"]]\n",
        "\n",
        "plt.figure(figsize=(13,6))\n",
        "plt.plot(tmp_99.index, tmp_99[\"r\"], label=\"Retornos\", alpha=0.6, linewidth=1)\n",
        "plt.plot(tmp_99.index, tmp_99[\"VaR_99\"], label=\"VaR 99%\", linewidth=1)\n",
        "plt.scatter(viol_99.index, viol_99[\"r\"], label=\"Violaciones 99%\", s=15)\n",
        "plt.title(\"Backtesting visual ‚Äî Violaciones VaR 99%\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# 16.3 Rolling hit rate (¬øse acerca a 1% o 5%?)\n",
        "# ============================================================\n",
        "\n",
        "window = 250  # 1 a√±o burs√°til aprox\n",
        "\n",
        "hit_95 = make_hits(df_var, \"VaR_95\", \"r\")\n",
        "\n",
        "roll_95 = hit_95.rolling(window).mean()\n",
        "roll_99 = hit_99.rolling(window).mean()\n",
        "\n",
        "plt.figure(figsize=(13,5))\n",
        "plt.plot(roll_95.index, roll_95.values, label=\"Rolling hit rate VaR 95% (esperado 5%)\")\n",
        "plt.plot(roll_99.index, roll_99.values, label=\"Rolling hit rate VaR 99% (esperado 1%)\")\n",
        "plt.title(f\"Rolling hit rate ({window} d√≠as)\")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# ============================================================\n",
        "# 16.4 Tabla simple: esperado vs observado\n",
        "# ============================================================\n",
        "\n",
        "for var_col, alpha in [(\"VaR_95\", 0.05), (\"VaR_99\", 0.01)]:\n",
        "    hit = make_hits(df_var, var_col)\n",
        "    T = hit.count()\n",
        "    x = hit.sum()\n",
        "    print(f\"{var_col}: Observadas={x} de {T} | Tasa={x/T:.4f} | Esperada={alpha:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58d879c7",
      "metadata": {},
      "source": [
        "# **Ap√©ndice A ‚Äî Forecast de Precio con ARIMA (opcional)**\n",
        "Este bloque no es central para VaR, pero se conserva como referencia exploratoria.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c401b2af",
      "metadata": {},
      "source": [
        "# BLOQUE 6 (Prueba) ‚Äî Forecast de precio (ARIMA sobre log_price)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b65269dd",
      "metadata": {},
      "outputs": [],
      "source": [
        "log_price = log_price.asfreq(\"B\").ffill()\n",
        "price = price.asfreq(\"B\").ffill()\n",
        "model = ARIMA(log_price, order=(3,0,0)) #### Cambiar ACA segun resultado del autoarima\n",
        "arima_fit = model.fit()\n",
        "print(arima_fit.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de02753f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "\n",
        "\n",
        "steps = 30\n",
        "\n",
        "fc = arima_fit.get_forecast(steps=steps)\n",
        "\n",
        "fc_mean_log = fc.predicted_mean\n",
        "fc_ci_log = fc.conf_int()\n",
        "\n",
        "# 1) Crear √≠ndice FUTURO (d√≠as h√°biles)\n",
        "future_idx = pd.bdate_range(start=log_price.index[-1] + pd.Timedelta(days=1), periods=steps)\n",
        "\n",
        "# 2) Volver a precio + poner √≠ndice futuro\n",
        "fc_price = pd.Series(np.exp(fc_mean_log.values), index=future_idx, name=\"fc_price\")\n",
        "lower    = pd.Series(np.exp(fc_ci_log.iloc[:,0].values), index=future_idx, name=\"lower\")\n",
        "upper    = pd.Series(np.exp(fc_ci_log.iloc[:,1].values), index=future_idx, name=\"upper\")\n",
        "\n",
        "forecast_df = pd.concat([fc_price, lower, upper], axis=1)\n",
        "print(forecast_df.head())\n",
        "\n",
        "# 3) Plot correcto (todo con fechas)\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(price, label=\"Precio hist√≥rico\")\n",
        "plt.plot(fc_price, label=\"Forecast precio\")\n",
        "plt.fill_between(future_idx, lower, upper, alpha=0.2, label=\"IC 95%\")\n",
        "plt.title(f\"Forecast de Precio ‚Äî {ticker} (ARIMA en log_price)\")\n",
        "plt.xlabel(\"Fecha\"); plt.ylabel(\"Precio\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}